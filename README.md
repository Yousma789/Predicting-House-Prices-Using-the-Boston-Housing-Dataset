# Predicting-House-Prices-Using-the-Boston-Housing-Dataset
Overview

This project implements regression models from scratch to predict house prices using the Boston Housing Dataset. The models built include Linear Regression, Random Forest, and XGBoost. The project also involves data preprocessing, model performance comparison, and feature importance visualization.

1️⃣ Data Preprocessing

Dataset Cleaning: Removed unnecessary columns and handled missing values.

Feature Engineering: Normalized numerical features for improved model performance.

Outlier Handling: Identified and removed outliers to enhance prediction accuracy.

2️⃣ Model Implementation (From Scratch)

✅ Linear Regression: Implemented using gradient descent without built-in libraries.
✅ Random Forest: Built a custom decision tree-based model for ensemble learning.
✅ XGBoost: Created an optimized boosting algorithm for better prediction accuracy.

3️⃣ Performance Evaluation

Models were evaluated using Root Mean Squared Error (RMSE) and R² Score.

Performance comparison was conducted to determine the best model.

4️⃣ Feature Importance Visualization

Visualized feature importance for Random Forest & XGBoost to identify key predictors of house prices.

Helped in understanding which features influence predictions the most.

Results & Conclusion

XGBoost performed the best in terms of accuracy and error minimization.

Key influencing factors include crime rate, number of rooms, and property tax rates.

Successfully implemented regression models without using pre-built machine learning libraries.

Deliverables

📂 Jupyter Notebook (.ipynb) – Full implementation.
📊 Visualizations (Feature Importance, Model Comparison, etc.)
📜 GitHub Repository & Kaggle Notebook Submission – For project tracking and sharing.

Final Thought

This project demonstrates strong data preprocessing, model building from scratch, performance evaluation, and visualization techniques, making it a valuable hands-on machine learning experience! 🚀
